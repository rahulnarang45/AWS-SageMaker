{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343f603d",
   "metadata": {},
   "source": [
    "## Steps to be followed for the project\n",
    "\n",
    "- Importing necessary Libraries\n",
    "- Creating S3 bucket\n",
    "- Mapping train And Test Data in S3\n",
    "- Mapping The path of the models in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "652da59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3 # with help of python from out local environment we can read the \"public\" S3 bucket\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "# we will load an image container which has XGBOOST algorithms and can be downloaded from get_image_uri \n",
    "\n",
    "from sagemaker.session import s3_input, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b92771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'bankapplication05312022'\n",
    "\n",
    "my_region= boto3.session.Session().region_name\n",
    "\n",
    "print(my_region)\n",
    "\n",
    "#to access the S3 bucket we need to create a session as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdea26dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error :  An error occurred (InvalidLocationConstraint) when calling the CreateBucket operation: The specified location-constraint is not valid\n"
     ]
    }
   ],
   "source": [
    "s3= boto3.resource('s3') #that's how we get the access of S3 bucket\n",
    "\n",
    "\n",
    "try:\n",
    "    if my_region == \"us-east-1\":\n",
    "        s3.create_bucket(Bucket=bucket_name,CreateBucketConfiguration={'LocationConstraint': 'us-east-1'})\n",
    "    print(' Bucket is created')\n",
    "\n",
    "except Exception as e:\n",
    "    print('S3 error : ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ae4167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bankapplication05312022/xgboost-as-a-built-in-algo/output\n"
     ]
    }
   ],
   "source": [
    "# set an output path where the trained model will be saved\n",
    "\n",
    "prefix = 'xgboost-as-a-built-in-algo'\n",
    "output_path ='s3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1103940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "#renaming the csv file to bank_clean\n",
    "\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "    \n",
    "    \n",
    "# data is downloaded into the instance i.e. our jupyter notebook ( which is running on an instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d46efdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "source": [
    "### Train Test split\n",
    "\n",
    "import numpy as np\n",
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1bcc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever we are working in sagemaker \"Dependent variable should be our 1st feature in dataframe\n",
    "### Saving Train And Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('train.csv', index=False, header=False)\n",
    "\n",
    "#accessing the s3 bucket and uploading\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "\n",
    "#now we have access the s3 bucket to get the path data or Data\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b239b492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.inputs.TrainingInput at 0x7f55a52d1c18>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_input_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754076cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We save with test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95c187fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "\n",
    "#accessing the s3 bucket and uploading\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "\n",
    "#now we have access the s3 bucket to get the path data or Data\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fd43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ffac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms are present in containers or as images. we hae to pull them into our instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9da0f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = get_image_uri(boto3.Session().region_name,'xgboost', repo_version='1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57817ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }\n",
    "\n",
    "\n",
    "#got this hyperparameters by EDA on local system as it would cost much on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SageMaker estimator that calls the xgboost-container\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(image_name=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.2xlarge', \n",
    "                                          train_volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          train_use_spot_instances=True,\n",
    "                                          train_max_run=300,\n",
    "                                          train_max_wait=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50522c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3f3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf85bee0",
   "metadata": {},
   "source": [
    "## Deploy Machine Learning Model As Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07153935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea6602f9",
   "metadata": {},
   "source": [
    "## Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defab45c",
   "metadata": {},
   "source": [
    "## Deleting The Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc08705",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9ea51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
